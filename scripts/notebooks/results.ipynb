{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first step is to obtain the project, and map each run to exactly which model, on which dataset, which fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykt.utils.wandb_utils import WandbUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! sweep falconcode_2_2_dkt_qid_4, was ran multiple times, taking the latest one :['bqtj3c4l', 'ouo2cgkb', '3wi059sz']\n",
      "Warning!! sweep falconcode_2_2_dkt_qid_3, was ran multiple times, taking the latest one :['fm9vipzn', 'iah0pw1h', 'rpxmti17']\n",
      "Warning!! sweep falconcode_2_2_dkt_qid_2, was ran multiple times, taking the latest one :['8lsdhg54', 'w7fya0bz', '1d5gtk7z']\n",
      "Warning!! sweep falconcode_2_2_dkt_qid_1, was ran multiple times, taking the latest one :['0vuv0tui', 'edsbgzk1', 't1w6xio5']\n",
      "Warning!! sweep falconcode_2_2_dkt_qid_0, was ran multiple times, taking the latest one :['68sluxig', 'vvkxc907', 'mcoykidl', 'dvw1l1d7']\n",
      "self.sweep_dict is {'falconcode_2_2_dkt_qid_4': 'bqtj3c4l', 'falconcode_2_2_dkt_qid_3': 'fm9vipzn', 'falconcode_2_2_dkt_qid_2': '8lsdhg54', 'falconcode_2_2_dkt_qid_1': '0vuv0tui', 'falconcode_2_2_dkt_qid_0': '68sluxig'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pykt.utils.wandb_utils.WandbUtils at 0x2b97d46b8750>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wu = WandbUtils('letech', 'kt_toolkits')\n",
    "wu.sweep_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We obtain a list of the datasets we used and the models trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'falconcode_2_2'}, {'dkt'})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets, models = set(), set()\n",
    "sweep_names = wu.sweep_dict.keys()\n",
    "for sn in sweep_names:\n",
    "    parts = sn.split(\"_\")\n",
    "    datasets.add(\"_\".join(parts[:3]))\n",
    "    models.add(\"_\".join(parts[3: parts.index(\"qid\")]))\n",
    "    \n",
    "datasets, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain for the given dataset, model, and folds, the best results\n",
    "\n",
    "We also need to know for that given model, what are the hyperparameters, so w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparameter_names(selected_sweeps):\n",
    "    _, model_configs = wu.get_df(selected_sweeps[0])\n",
    "    rejected_paramters = [\"model_name\", \"dataset_name\", \"save_dir\", \"fold\", \"seed\"]\n",
    "    hyperparameters = [k for k in model_configs if k not in rejected_paramters]\n",
    "    return hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_hyperparameters(grouped_results, hyperparams):\n",
    "    best_hyperparams = grouped_results.groupby(hyperparams)[\"validauc\"].mean().to_frame()\n",
    "    best_hyperparams = best_hyperparams.sort_values(by=\"validauc\", ascending=False)\n",
    "    best_hyperparams = best_hyperparams.head(1).index\n",
    "    best_hyperparams = best_hyperparams.to_frame().reset_index(drop=True).iloc[0].to_dict()\n",
    "    query_best_hyperparams = \" & \".join([f\"({k}=={repr(v)})\" for k, v in best_hyperparams.items()])\n",
    "    return best_hyperparams#, query_best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_finnished(selected_sweeps):\n",
    "    for ss in selected_sweeps:\n",
    "        status = wu.get_sweep_info(ss)[\"state\"]\n",
    "        if status != \"FINISHED\":\n",
    "            message = \"Careful sweep \" + ss + \" hasn't finnished yet\"\n",
    "            warn(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4821/1632450084.py:6: UserWarning: Careful sweep falconcode_2_2_dkt_qid_2 hasn't finnished yet\n",
      "  warn(message)\n",
      "/tmp/ipykernel_4821/1632450084.py:6: UserWarning: Careful sweep falconcode_2_2_dkt_qid_1 hasn't finnished yet\n",
      "  warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('falconcode_2_2', 'dkt'): {'dropout': 0.05,\n",
       "  'emb_size': 64,\n",
       "  'emb_type': 'qid',\n",
       "  'learning_rate': 0.001}}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "best_hyperparams = {}\n",
    "for dataset_name, model_name in product(datasets, models):\n",
    "    selected_sweeps = [sn for sn in sweep_names \n",
    "                       if dataset_name in sn and model_name in sn]\n",
    "    check_all_finnished(selected_sweeps)\n",
    "    grouped_results = pd.concat(wu.get_multi_df(selected_sweeps))\n",
    "    hyperparameters = get_hyperparameter_names(selected_sweeps)\n",
    "    bests = get_best_hyperparameters(grouped_results, \n",
    "                                     hyperparameters)\n",
    "    best_hyperparams[(dataset_name, model_name)] = bests\n",
    "    \n",
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end here we have a mapping of the hyperparameters to rerun model training with, which we will save somewhere in a file or a dictionary. We can then pass this dictionary to another training script which will run the model trainings with the good hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pykt)",
   "language": "python",
   "name": "pykt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
